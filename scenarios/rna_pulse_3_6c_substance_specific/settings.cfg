[case-study]
package = ..
name = tktd_rna_pulse
scenario = rna_pulse_3_6c_substance_specific
observations = tox.db
simulation = SingleSubstanceSim2

[simulation]
# model specification
# --------------------
y0 = cext=cext cint=Array([0]) nrf2=Array([1]) P=Array([0])
model = tktd_rna_3_6c
modeltype = deterministic
solver = simplified_ode_solver
solver_post_processing = calculate_psurv2
seed = 1
prior_dimensions = substance
substance = diuron diclofenac naproxen

# data selection
# --------------------
apical_effect = lethal
hpf = 24

# experiment selection
# --------------------
# the IDs may change when the database is rewritten. Therefore it is potentially
# unsafe to exclude experiments by ID. Better would be a (name, date) pair. Or
# even better would be not to overwrite the database each time I change the layout,
# but to modify the database.
# eid=2 is the Diuron experiment by Kodritsch. This has quite a different relation
# between Ci and Ce. Assuming cext_nom here would probably be better.
# Kodritsch data has IDs: 1,2,3,7,10
# Knapp Data from Diclofenac are also extremely differen
exclude_experiments = 15 16 18 31 42 45 46 2 37 38 39
exclude_treatments = 205


[data-structure]
cext = dimensions=[id,time] min=0 max=nan observed=True
cint = dimensions=[id,time] min=0 max=nan observed=True
nrf2 = dimensions=[id,time] min=0 max=nan observed=True
P = dimensions=[id,time] min=0 max=nan observed=False
survival = dimensions=[id,time] min=0 max=1 observed=True
# evaluator_dim_order = id time substance

[model-parameters]
# IN THIS SCNEARIO PRIORS ARE DEFINED IN THE USER_DEFINED_PROBABILITY_MODEL
# prob.model_rna_pulse_3_nb_independent
k_i = value=[5.0,0.5,0.5] prior=lognorm(scale=[5.0,0.5,0.5],s=1)

# RNA model parameters
# RNA transcription rate
r_rt = value=[0.1,0.1,0.1] prior=lognorm(scale=[0.1,0.1,0.1],s=2)

# RNA decay
r_rd = value=[0.5,0.5,0.5] prior=lognorm(scale=[0.5,0.5,0.5],s=2)

# responsiveness of activation
v_rt = value=[1.0,1.0,1.0] prior=lognorm(scale=[1.0,1.0,1.0],s=2)

# Concentratrion threshold for gene activation
z_ci = value=[200.0,50.0,3000.0] prior=lognorm(scale=[200.0,50.0,3000.0],s=2)

# RNA decay
k_p = value=[0.1,0.02,0.02] prior=lognorm(scale=[0.02,0.02,0.02],s=2)

# Metabolization
k_m = value=[0.01,0.01,0.01] prior=lognorm(scale=[0.01,0.01,0.01],s=2)

# SD parameters
h_b = value=[0.0000001,0.0000001,0.0000001] prior=lognorm(scale=[0.00000001,0.0000001,0.0000001],s=2)
z = value=[1,1,1] prior=lognorm(scale=[1,1,1],s=1)
kk = value=[0.02,0.02,0.02] prior=lognorm(scale=[0.02,0.02,0.02],s=3)

# this is the same noise for all substances. Under the current model specification
# it can't be modeled any other way. Another assumption would be weird anyways
sigma_cint = value=[0.5,0.5,0.5] prior=halfnorm(scale=[5,5,5])
sigma_nrf2 = value=[0.1,0.1,0.1] prior=halfnorm(scale=[5,5,5])

# fixed model parameters
ci_max = value=[1757.0,168.1,6364.8] free=False
r_0 = value=1.0 free=False

[error-model]
cint = lognorm(scale=cint+EPS,s=sigma_cint)
nrf2 = lognorm(scale=nrf2,s=sigma_nrf2)
lethality = binom(p=lethality,n=nzfe)

[multiprocessing]
cores = 1

[inference]
backend = numpyro
extra_vars = nzfe substance_index survivors_before_t
EPS=1e-8
objective_function = objective_average
n_objectives = 1
n_predictions = 1000
plot_function = pyabc_posterior_predictions

[inference.pyabc]
population_size = 100
minimum_epsilon = 0.00001
min_eps_diff = 0.0000001
max_nr_populations = 100
sampler = SingleCoreSampler
database_path = pyabc.db
eval.model_id = 0
eval.history_id = -1
eval.n_predictions = 1000
plot_function = pyabc_posterior_predictions

[inference.pyabc.redis]
port = 1803
password = simulate

[inference.pymoo]
population_size = 1000
max_nr_populations = 100
algorithm = UNSGA3
ftol = 0.01
xtol = 0.001
verbose = True

[inference.numpyro]
user_defined_probability_model = model_rna_pulse_3_6c_substance_specific
user_defined_preprocessing = cint_max_preprocessing
gaussian_base_distribution = 1
kernel = svi
# With 'svi' or 'map' the model should run with roundabout 20-30 iterations per second. 
# In the init phase this can be around 10 iterations. Slower model evaluations indicate
# that the model is not converging correctly and is perhaps stuck on a local optimum
svi_iterations = 20000
svi_learning_rate = 0.01
chains = 1
draws = 2000
